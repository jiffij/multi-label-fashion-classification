{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI6126 Project 1 Fashion Attributes Classification Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lu Cheuk Fung Jeff G2304245F clu014@e.ntu.edu.sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from transformers import AutoModel, SwinModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The box below will control everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING = False # True: training\n",
    "EVALUATE = True # True: calculate the validation loss and accuracy\n",
    "PRINTING = True # True: print the 'prediction.txt'\n",
    "MODEL_NAME = \"test\" # The checkpoint file name if you are training a model\n",
    "LOAD_CHECKPOINT = 'Swin_large_68_cont_best.pth' # This will be the checkpoint path used if you are evaluation or printing\n",
    "IMG_DIR = os.path.join(\"FashionDataset\", \"FashionDataset\",\"img\")# The directory of images of the dataset, default \"FashionDataset/FashionDataset/img\" \n",
    "SPLIT_DIR = os.path.join(\"FashionDataset\", \"FashionDataset\",\"split\")  # The directory of the labels of the dataset, default \"FashionDataset/FashionDataset/split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "learning_rate = 1e-5 #0.001 1e-4 1e-5(good) 5e-6(best)\n",
    "momentum = (0.9, 0.999)\n",
    "wd = 1e-5 # 1e-5(good) 5e-4(best)\n",
    "EPOCHS = 50\n",
    "retrain = False\n",
    "SWIN = True # 1st\n",
    "XCEPTION = False # 2nd\n",
    "ONEHOT = True # label = 26 if True\n",
    "CROSS = False # cross entropy if True, bcewithlogitsloss otherwise\n",
    "swin_model = ['swin-tiny-patch4-window7-224', 'swin-large-patch4-window7-224', 'swin-base-patch4-window7-224', 'swinv2_base']\n",
    "swin_hidden_size = [768, 1536, 1024, 1536]\n",
    "swinmodel = 1\n",
    "IMAGE_SIZE = 224 if SWIN and swinmodel !=3 else 256 if SWIN else 299\n",
    "use_weight = False # use bce weight\n",
    "checkpoint_name = MODEL_NAME\n",
    "drop_ratio = 0.35 #0.35\n",
    "two_layer = False\n",
    "batch_norm = False\n",
    "MIXUP = True\n",
    "lr_scheduler = False\n",
    "early_stopping = 7\n",
    "mean = [0.7657, 0.7359, 0.7254]\n",
    "std = [0.2838, 0.2965, 0.3026]\n",
    "\n",
    "retrain_checkpoint = 'xception_checkpoint_ep7.pth'\n",
    "# bce_weight = torch.tensor([5.51041659e+00, 4.86166466e+00, 1.39700595e+01, 1.08483410e+01,\n",
    "#        4.48715555e+01, 1.07641196e+00, 4.61698070e+01, 2.28299408e+00,\n",
    "#        4.80046398e+00, 9.12045886e-01, 9.24590145e+00, 4.25762351e+00,\n",
    "#        4.04099971e-01, 1.39693192e+00, 5.05326870e+00, 2.62157757e+02,\n",
    "#        1.41662638e+00, 1.51290318e+01, 6.12250704e+00, 4.71020887e-01,\n",
    "#        4.66190432e+01, 1.03166645e+02, 1.04678897e+01, 5.67556735e+00,\n",
    "#        1.69211463e+01, 2.58811681e-01], dtype=torch.float32)#torch.ones(26) #\n",
    "\n",
    "bce_weight = torch.tensor([2.32820056, 2.27380113, 2.73221439, 2.62237946, 3.23898725,\n",
    "       1.61899464, 3.25137419, 1.94552092, 2.26829935, 1.54703282,\n",
    "       2.55296539, 2.21618339, 1.19350495, 1.73219137, 2.29058852,\n",
    "       4.00557884, 1.73827145, 2.76682727, 2.37394542, 1.2600563,\n",
    "       3.25557949, 3.60055544, 2.60687527, 2.34102541, 2.81544591,\n",
    "       1.        ], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(os.path.join(SPLIT_DIR, \"train.txt\"), names=[\"x\", ])\n",
    "val_csv = pd.read_csv(os.path.join(SPLIT_DIR, \"val.txt\"), names=[\"x\",])\n",
    "test_csv = pd.read_csv(os.path.join(SPLIT_DIR, \"test.txt\"), names=[\"X\",])\n",
    "train_attr_csv = pd.read_csv(os.path.join(SPLIT_DIR, \"train_attr.txt\"), delimiter=\" \", names=['c1', 'c2', 'c3', 'c4', 'c5', 'c6'])\n",
    "val_attr_csv = pd.read_csv(os.path.join(SPLIT_DIR, \"val_attr.txt\"), delimiter=' ', names=['c1', 'c2', 'c3', 'c4', 'c5', 'c6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00002.jpg'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.iloc[2, 0].split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 0, 2, 0, 2, 2]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_attr_csv.iloc[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_to_onehot(vec, flatten):\n",
    "    if flatten:\n",
    "        onehot = torch.zeros(26, dtype=torch.float32)\n",
    "        onehot[vec[0]] = 1\n",
    "        onehot[vec[1]+7] = 1\n",
    "        onehot[vec[2]+10] = 1\n",
    "        onehot[vec[3]+13] = 1\n",
    "        onehot[vec[4]+17] = 1\n",
    "        onehot[vec[5]+23] = 1\n",
    "    else:\n",
    "        onehot = torch.tensor(vec, dtype=torch.float32)\n",
    "    return onehot\n",
    "\n",
    "def select_attr(Mat, flatten):\n",
    "    if flatten:\n",
    "        vec = torch.zeros(Mat.shape[0], 6)\n",
    "        vec[:, 0] = torch.argmin(torch.abs(1 - Mat[:, :7]), dim=1)\n",
    "        vec[:, 1] = torch.argmin(torch.abs(1 - Mat[:, 7:10]), dim=1)\n",
    "        vec[:, 2] = torch.argmin(torch.abs(1 - Mat[:, 10:13]), dim=1)\n",
    "        vec[:, 3] = torch.argmin(torch.abs(1 - Mat[:, 13:17]), dim=1)\n",
    "        vec[:, 4] = torch.argmin(torch.abs(1 - Mat[:, 17:23]), dim=1)\n",
    "        vec[:, 5] = torch.argmin(torch.abs(1 - Mat[:, 23:]), dim=1)\n",
    "    else:\n",
    "        vec = torch.round(Mat)\n",
    "    return vec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, img_dir, X, y, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_df = X\n",
    "        self.labels_df = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.img_df.iloc[idx, 0].split('/')[1])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        labels = vec_to_onehot(self.labels_df.iloc[idx].tolist(), ONEHOT) # torch.tensor(self.labels_df.iloc[idx].tolist(), dtype=torch.int32)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_loader(batch_size, seed=1):\n",
    "    training_transformation = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(30),  # Rotate the image by a random angle between -10 and 10 degrees\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Randomly change brightness, contrast, saturation, and hue\n",
    "        # transforms.RandomAffine(degrees=20, translate=(0.2, 0.2), scale=(0.8, 1.2), shear=10), # last added\n",
    "        # transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.5),\n",
    "        transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0), ratio=(0.9, 1.1)),  # Randomly crop and resize the image\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "        # transforms.Normalize(training_set_mean, training_set_std)\n",
    "    ])\n",
    "    valid_transformation = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "        # transforms.Normalize(training_set_mean, training_set_std)\n",
    "    ])\n",
    "    test_transformation = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "        # transforms.Normalize(training_set_mean, training_set_std)\n",
    "    ])\n",
    "    train_set = FashionDataset(IMG_DIR, train_csv, train_attr_csv, transform=training_transformation)\n",
    "    validation_set = FashionDataset(IMG_DIR, val_csv, val_attr_csv, transform=valid_transformation)\n",
    "    test_set = FashionDataset(IMG_DIR, test_csv, val_attr_csv, transform=test_transformation)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = get_train_valid_loader(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pretrained model\n"
     ]
    }
   ],
   "source": [
    "if retrain:\n",
    "    print(\"retrain\")\n",
    "    model = timm.create_model('xception41', pretrained=False, num_classes=(26 if ONEHOT else 6))\n",
    "    model.cuda()\n",
    "    if ONEHOT:\n",
    "        if not CROSS:\n",
    "            criterion = torch.nn.BCEWithLogitsLoss(weight=(bce_weight if use_weight else None))#weight=bce_weight.cuda()\n",
    "        else:\n",
    "            print(\"Cross Entropy\")\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        criterion = nn.MSELoss().cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=momentum, weight_decay=wd)\n",
    "\n",
    "    # Load model checkpoint\n",
    "    checkpoint = torch.load(retrain_checkpoint)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    # loss = checkpoint['loss']\n",
    "    print(\"loaded pretrained weight\")\n",
    "else:\n",
    "    if not SWIN:\n",
    "        # model = timm.create_model(\"hf_hub:timm/xception41.tf_in1k\", pretrained=True, num_classes=(26 if ONEHOT else 6))\n",
    "        if XCEPTION:\n",
    "            pretrained_cfg_overlay = {'file' : r\"./model/xception71.tf_in1k/pytorch_model.bin\"}\n",
    "            model = timm.models.create_model('xception71.tf_in1k', pretrained=True, pretrained_cfg_overlay=pretrained_cfg_overlay, num_classes=(26 if ONEHOT else 6))\n",
    "        else:\n",
    "            pretrained_cfg_overlay = {'file' : r\"./model/inceptionv3/pytorch_model.bin\"}\n",
    "            model = timm.models.create_model('inception_v3.tf_in1k', pretrained=True, pretrained_cfg_overlay=pretrained_cfg_overlay, num_classes=(26 if ONEHOT else 6))\n",
    "        # model = timm.create_model(\"xception41.tf_in1k\", pretrained=True, num_classes=(26 if ONEHOT else 6))\n",
    "    else:\n",
    "        swin = SwinModel.from_pretrained(swin_model[swinmodel], local_files_only=True)\n",
    "    print(\"loaded pretrained model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelSwin(nn.Module):\n",
    "    def __init__(self, swin):\n",
    "        super(MultilabelSwin, self).__init__()\n",
    "        # self.num_classes = 26\n",
    "        self.transformer = swin\n",
    "        self.dropout = nn.Dropout(p=drop_ratio)\n",
    "        hidden_channel = 300\n",
    "        if batch_norm:\n",
    "            self.bn2 = nn.BatchNorm1d(swin_hidden_size[swinmodel])\n",
    "        if two_layer:\n",
    "            self.fc2 = nn.Linear(swin_hidden_size[swinmodel], hidden_channel)\n",
    "            self.bn1 = nn.BatchNorm1d(hidden_channel)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.fc1 = nn.Linear(hidden_channel, 26 if ONEHOT else 6)\n",
    "            self.dropout2 = nn.Dropout(p=drop_ratio)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(swin_hidden_size[swinmodel], 26 if ONEHOT else 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer(x)\n",
    "        x = x.pooler_output\n",
    "        if batch_norm:\n",
    "            x = self.bn2(x)\n",
    "        x = self.dropout(x)\n",
    "        if two_layer:\n",
    "            x = self.fc2(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SWIN:\n",
    "    model = MultilabelSwin(swin)\n",
    "    \n",
    "# Load model checkpoint\n",
    "if not TRAINING:\n",
    "    checkpoint = torch.load(LOAD_CHECKPOINT)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded to cuda\n",
      "BCEWithLogitsLoss\n"
     ]
    }
   ],
   "source": [
    "if not retrain:\n",
    "    print(\"loaded to cuda\")\n",
    "    model.cuda()\n",
    "    if ONEHOT:\n",
    "        if not CROSS:\n",
    "            print(\"BCEWithLogitsLoss\")\n",
    "            criterion = torch.nn.BCEWithLogitsLoss(weight=(bce_weight if use_weight else None)).cuda()\n",
    "            val_criterion = torch.nn.BCEWithLogitsLoss().cuda()\n",
    "        else:\n",
    "            print(\"cross entropy\")\n",
    "            criterion = nn.CrossEntropyLoss().cuda()\n",
    "            val_criterion = nn.CrossEntropyLoss().cuda()\n",
    "    else:\n",
    "        print(\"MSELoss\")\n",
    "        criterion = nn.MSELoss().cuda()\n",
    "        val_criterion = nn.MSELoss().cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=momentum, weight_decay=wd)\n",
    "else:\n",
    "    print(\"nothing done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_accuracy(y_pred, y_true, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculate the multi-label accuracy given the predicted and true labels.\n",
    "    \n",
    "    Args:\n",
    "    - y_pred (torch.Tensor): Predicted labels (probabilities) from the model. Shape (batch_size, num_classes).\n",
    "    - y_true (torch.Tensor): True labels (binary) for each sample. Shape (batch_size, num_classes).\n",
    "    - threshold (float): Threshold value for determining the predicted labels.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Multi-label accuracy.\n",
    "    \"\"\"\n",
    "    # Apply threshold to predicted labels\n",
    "    y_pred_labels = (y_pred > threshold).float()\n",
    "    \n",
    "    # Calculate accuracy for each sample\n",
    "    sample_accuracy = torch.sum(y_pred_labels == y_true, dim=1).float()/y_true.shape[1]\n",
    "    # sample_accuracy = correct_samples == y_true.shape[1]\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    accuracy = torch.mean(sample_accuracy.float(), dim=0)\n",
    "    \n",
    "    return accuracy.item()\n",
    "\n",
    "def multi_category_accuracy(y_pred, y_true):\n",
    "    Y_pred = select_attr(y_pred, ONEHOT)\n",
    "    Y_true = select_attr(y_true, ONEHOT)\n",
    "    return torch.mean(torch.sum(Y_pred == Y_true, dim=1).float()/Y_true.shape[1], dim=0).item()\n",
    "\n",
    "# evaluation\n",
    "def compute_avg_class_acc(y_pred, y_true):\n",
    "    # if ONEHOT:\n",
    "    pred_labels = select_attr(y_pred, ONEHOT)\n",
    "    gt_labels = select_attr(y_true, ONEHOT)\n",
    "\n",
    "    # print(pred_labels[1], gt_labels[1])\n",
    "    # else: \n",
    "    #     pred_labels = y_pred\n",
    "    #     gt_labels = y_true\n",
    "    \n",
    "    num_attr = 6\n",
    "    num_classes = [7, 3, 3, 4, 6, 3]  # number of classes in each attribute\n",
    "    \n",
    "    per_class_acc = []\n",
    "    for attr_idx in range(num_attr):\n",
    "        for idx in range(num_classes[attr_idx]):\n",
    "            target = gt_labels[:, attr_idx]#.cpu().detach().numpy()\n",
    "            pred = pred_labels[:, attr_idx]#.cpu().detach().numpy()\n",
    "            correct = torch.sum((target == pred) * (target == idx))\n",
    "            total = torch.sum(target == idx)\n",
    "            # print(correct, total)\n",
    "            per_class_acc.append(float(correct) / float(total) if float(total) != 0 else float(1))  # if float(correct) != float(0) else float(0)\n",
    "\n",
    "    return sum(per_class_acc) / len(per_class_acc)\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    # Generate a random weight for mixing the data\n",
    "    # lam = torch.rand(x.size(0), 1).to(x.device)\n",
    "    lam = torch.rand(1).to(x.device)\n",
    "    lam = torch.max(lam, 1 - lam)\n",
    "    \n",
    "    # Generate a mixed image\n",
    "    mixed_x = lam * x + (1 - lam) * x.flip(dims=(0,))\n",
    "    \n",
    "    # Generate mixed labels\n",
    "    y_a, y_b = y, y.flip(dims=(0,))\n",
    "    mixed_y = lam * y_a + (1 - lam) * y_b\n",
    "    \n",
    "    return mixed_x, mixed_y, y_a, y_b, lam\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_training_loss = []\n",
    "stat_val_loss = []\n",
    "stat_training_acc = []\n",
    "stat_val_acc = []\n",
    "best_val_acc = 0\n",
    "best_val_loss = float('inf')\n",
    "partition = [0, 7, 10, 13, 17, 23, 26]\n",
    "num_attr = 6\n",
    "best_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "\n",
    "    if lr_scheduler:\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, EPOCHS)\n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(EPOCHS):\n",
    "            training_loss = 0\n",
    "            training_acc = 0\n",
    "            batch_num = 0\n",
    "            val_loss = 0\n",
    "            val_acc = 0\n",
    "            val_batch_num = 0\n",
    "            # training\n",
    "            model.train()\n",
    "            for imgs, labels in train_loader:\n",
    "\n",
    "                imgs = imgs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "                if MIXUP:\n",
    "                    imgs, labels, y_a, y_b, lam = mixup_data(imgs, labels)\n",
    "            \n",
    "                batch_size = imgs.shape[0]\n",
    "                optimizer.zero_grad()\n",
    "                logits = model.forward(imgs)\n",
    "                loss = None\n",
    "                if CROSS:\n",
    "                    for i in range(num_attr):\n",
    "                        if loss == None:\n",
    "                            loss = criterion(logits[:, partition[i] : partition[i+1]], labels[:, partition[i] : partition[i+1]])\n",
    "                        else:\n",
    "                            loss += criterion(logits[:, partition[i] : partition[i+1]], labels[:, partition[i] : partition[i+1]])\n",
    "                elif MIXUP:\n",
    "                    loss = lam * criterion(logits, y_a) + (1 - lam) * criterion(logits, y_b)\n",
    "                else:\n",
    "                    loss = criterion(logits, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                training_acc += compute_avg_class_acc(logits, labels)#multi_label_accuracy(logits, labels) #\n",
    "                \n",
    "                training_loss += loss.item()\n",
    "                batch_num += 1\n",
    "                \n",
    "            # validation\n",
    "            model.eval()\n",
    "            for val_imgs, val_labels in valid_loader:\n",
    "                \n",
    "                val_imgs = val_imgs.cuda()\n",
    "                val_labels = val_labels.cuda()\n",
    "                \n",
    "                batch_size = val_imgs.shape[0]\n",
    "                val_logits = model.forward(val_imgs)\n",
    "                loss = val_criterion(val_logits, val_labels)\n",
    "                val_acc += compute_avg_class_acc(val_logits.cuda(), val_labels)#multi_label_accuracy(val_logits.cuda(), val_labels) #\n",
    "                val_loss += loss.item()\n",
    "                val_batch_num += 1\n",
    "            # assert val_batch_num == 10000\n",
    "            # update stats\n",
    "            stat_training_loss.append(training_loss/batch_num)\n",
    "            stat_val_loss.append(val_loss/val_batch_num)\n",
    "            stat_training_acc.append(training_acc/batch_num)\n",
    "            stat_val_acc.append(val_acc/val_batch_num)\n",
    "            # print\n",
    "            print(f\"Epoch {(epoch+1):d}/{EPOCHS:d}.. Train loss: {(training_loss/batch_num):.4f}.. Train acc: {(training_acc/batch_num):.4f}.. Val loss: {(val_loss/val_batch_num):.4f}.. Val acc: {(val_acc/val_batch_num):.4f}\")\n",
    "            # lr scheduler\n",
    "            if lr_scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "            if epoch > 0 and best_val_loss > val_loss/val_batch_num : # val_acc/val_batch_num > best_val_acc\n",
    "                best_val_acc = val_acc/val_batch_num\n",
    "                best_val_loss = val_loss/val_batch_num\n",
    "                best_epoch = epoch\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss\n",
    "                }, f'{checkpoint_name}_best.pth')\n",
    "            if epoch > 0 and epoch - best_epoch >= early_stopping:\n",
    "                break\n",
    "        # save checkpoint every 8 step\n",
    "            # if epoch%8 == 0 and epoch > 0:\n",
    "            #     torch.save({\n",
    "            #         'model_state_dict': model.state_dict(),\n",
    "            #         'optimizer_state_dict': optimizer.state_dict(),\n",
    "            #         'loss': loss\n",
    "            #     }, f'{checkpoint_name}_ep{epoch}.pth')\n",
    "\n",
    "    print('Time: ', time.time() - start)\n",
    "    np.savez(f'{checkpoint_name}.npz', stat_training_loss=stat_training_loss, stat_val_loss=stat_val_loss, stat_training_acc=stat_training_acc, stat_val_acc=stat_val_acc)\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Not Training...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8176965933605127 .. Loss: 0.003741858061403036\n"
     ]
    }
   ],
   "source": [
    "if EVALUATE:\n",
    "    loader = valid_loader\n",
    "    MIXUP = False\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        category_acc = 0\n",
    "        acc = 0\n",
    "        loss = 0\n",
    "        batch_num = 0\n",
    "        for imgs, labels in loader:\n",
    "            \n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            if MIXUP:\n",
    "                imgs, labels, y_a, y_b, lam = mixup_data(imgs, labels)\n",
    "\n",
    "            logits = model.forward(imgs)\n",
    "            if MIXUP:\n",
    "                loss = lam * criterion(logits, y_a) + (1 - lam) * criterion(logits, y_b)\n",
    "            else:\n",
    "                loss = criterion(logits, labels)\n",
    "            # loss = criterion(logits, labels)\n",
    "            acc += compute_avg_class_acc(logits.cuda(), labels)\n",
    "            loss += loss.item()\n",
    "            batch_num += 1\n",
    "        print(f\"Accuracy: {acc/batch_num} .. Loss: {loss/batch_num}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model checkpoint\n",
    "# checkpoint = torch.load(f'{checkpoint_name}_best.pth')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# # loss = checkpoint['loss']\n",
    "# epoch = checkpoint['epoch']\n",
    "# print(epoch)\n",
    "\n",
    "if PRINTING:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        def print_to_csv(y_pred):\n",
    "            res = select_attr(y_pred, ONEHOT)\n",
    "            with open('prediction.txt', 'a') as file:\n",
    "                file.write('\\n'.join([' '.join(map(str, row)) for row in res.to(torch.int).numpy()])) # np.array2string(res.numpy())\n",
    "                file.write(\"\\n\")\n",
    "\n",
    "        model.eval()\n",
    "        category_acc = 0\n",
    "        test_acc = 0\n",
    "        test_loss = 0\n",
    "        batch_count = 0\n",
    "        for test_imgs, test_labels in test_loader:\n",
    "            \n",
    "            test_imgs = test_imgs.cuda()\n",
    "            test_labels = test_labels.cuda()\n",
    "            \n",
    "            # batch_size = val_imgs.shape[0]\n",
    "            test_logits = model.forward(test_imgs)\n",
    "            # loss = criterion(val_logits, val_labels)\n",
    "            print_to_csv(test_logits)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
